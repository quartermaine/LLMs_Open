{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quartermaine/LLMs_Open/blob/main/Code_Base_Anlyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -- START NOTEBOOK"
      ],
      "metadata": {
        "id": "Mkv6AhJgrLtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GitHub Repository Analyzer 🤖\n",
        "\n",
        "### **Description**\n",
        "\n",
        "The GitHub Repository Analyzer is a Gradio-powered application designed to analyze the software architecture of any GitHub repository. The analysis is powered by models deployed on Azure OpenAI.\n",
        "\n",
        "### **Features**\n",
        "\n",
        "✅ User-Friendly Interface – Provide a GitHub repository URL and receive a structured architectural analysis.\n",
        "\n",
        "✅ Codebase Parsing – Automatically converts the repository's code into a structured format for analysis.\n",
        "\n",
        "✅ LLM-Powered Analysis – Uses Azure OpenAI models to generate insights into the repository’s software architecture.\n",
        "\n",
        "✅ Markdown Output – Presents the analysis in a clear, well-formatted markdown format.\n",
        "\n",
        "### **How to Use**\n",
        "\n",
        "1️⃣ Start the Tool – Run the provided code in your Google Colab notebook to launch the GitHub Repository Analyzer.\n",
        "\n",
        "2️⃣ Enter Repository URL – Input the GitHub repository URL into the text box.\n",
        "\n",
        "3️⃣ Submit Your Query – Click the \"Submit\" button. The agent will clone the repository, analyze its structure, and generate an architectural breakdown.\n",
        "\n",
        "4️⃣ Review the Output – The structured markdown analysis will be displayed in the output field.\n",
        "\n",
        "### **Handling Errors & Limitations**\n",
        "\n",
        "🚨 Repository Size Limitation – Due to prompt size constraints, very large repositories may cause errors. If the repository is too big, the LLM might not be able to process the full codebase, leading to incomplete analysis or failures. Consider analyzing a smaller repository or breaking the analysis into smaller parts.\n",
        "\n",
        "🚨 Other Errors – If you encounter an issue (e.g., cloning failures or API timeouts), verify your environment variables and try again with a different repository.\n",
        "\n",
        "### **Adding Environment Variables**\n",
        "\n",
        "Define the following environment variables in the secrets section of your Google Colab notebook:\n",
        "\n",
        "🔑 OPENAI_API_KEY – Your Azure OpenAI API key.\n",
        "\n",
        "🔗 AZURE_OPENAI_ENDPOINT – Your Azure OpenAI deployment endpoint URL.\n",
        "\n",
        "📌 DEPLOYMENT_NAME – The name of your Azure OpenAI deployment.\n",
        "\n",
        "⚙️ OPENAI_API_TYPE – The API type (for this notebook, it is \"azure\").\n",
        "\n",
        "📅 OPENAI_API_VERSION – The Azure OpenAI API version.\n",
        "\n",
        "By setting up these environment variables, you ensure seamless integration and functionality of the GitHub Repository Analyzer CrewAI Agent.\n"
      ],
      "metadata": {
        "id": "K-ijRqROsFfS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "muxNUtearU_Y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install libraries\n",
        "\n",
        "%%capture\n",
        "!pip install py-llm-core llm-components gitpython gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "huZECyX5tXOF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import modules\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from textwrap import fill\n",
        "from dataclasses import dataclass\n",
        "from google.colab import userdata\n",
        "from typing import List\n",
        "import gradio as gr\n",
        "from git import Repo\n",
        "import json\n",
        "# map_codebase_to_text converts a codebase directory into structured markdown text.\n",
        "from llm_components.loaders.code_base import map_codebase_to_text\n",
        "# Import AzureOpenAIAssistant from py-llm-core.\n",
        "from llm_core.assistants import AzureOpenAIAssistant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2f3HU6lRtKm0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Set env vatiables\n",
        "\n",
        "# Set Azure OpenAI configuration\n",
        "os.environ['AZURE_OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['MODEL_NAME'] = userdata.get('DEPLOYMENT_NAME')\n",
        "os.environ['AZURE_OPENAI_API_TYPE'] = userdata.get('OPENAI_API_TYPE')\n",
        "os.environ['AZURE_OPENAI_API_VERSION'] = userdata.get('OPENAI_API_VERSION')\n",
        "os.environ['AZURE_OPENAI_ENDPOINT'] = userdata.get('AZURE_OPENAI_ENDPOINT')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4APde0YmtB9s",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Define helper functions\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Data classes definition\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class LowLevelModule:\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "@dataclass\n",
        "class HighLevelModule:\n",
        "    name: str\n",
        "    description: str\n",
        "    sub_modules: List[LowLevelModule]\n",
        "\n",
        "@dataclass\n",
        "class SoftwareArchitecture:\n",
        "    # System prompt and main prompt templates.\n",
        "    system_prompt: str = \"You are a software architect\"\n",
        "    prompt: str = (\n",
        "        \"Code base:\\n{code_base}\\n----\\n\\n\"\n",
        "        \"Analyze this code base and carefully write a description of the software architecture.\"\n",
        "    )\n",
        "    name: str = \"\"\n",
        "    description: str = \"\"\n",
        "    modules: List[HighLevelModule] = None\n",
        "\n",
        "    def to_markdown(self) -> str:\n",
        "        lines = [\n",
        "            f\"# {self.name}\\n\\n\",\n",
        "            f\"{fill(self.description, width=60)}\\n\\n\",\n",
        "        ]\n",
        "        if self.modules:\n",
        "            for module in self.modules:\n",
        "                lines.append(f\"## {module.name}\\n\\n\")\n",
        "                lines.append(f\"**Description:** {fill(module.description, width=60)}\\n\\n\")\n",
        "                lines.append(\"### Sub-modules\\n\\n\")\n",
        "                for sub_module in module.sub_modules:\n",
        "                    lines.append(f\"**{sub_module.name}**\\n\\n\")\n",
        "                    lines.append(f\"{fill(sub_module.description, width=60)}\\n\\n\")\n",
        "        return \"\".join(lines)\n",
        "\n",
        "# -----------------------------\n",
        "# Utility Functions\n",
        "# -----------------------------\n",
        "def clone_repository(repo_url: str, clone_dir: Path):\n",
        "    \"\"\"\n",
        "    Clone the given GitHub repository URL into the specified directory.\n",
        "    \"\"\"\n",
        "    Repo.clone_from(repo_url, str(clone_dir), depth=1)\n",
        "\n",
        "def analyze_repository(repo_url: str) -> str:\n",
        "    \"\"\"\n",
        "    Clones the GitHub repository, converts its code base to text, then uses an LLM to analyze the software architecture.\n",
        "    Returns the analysis as markdown.\n",
        "    \"\"\"\n",
        "    # Create a temporary directory for cloning the repo.\n",
        "    with tempfile.TemporaryDirectory() as temp_dir:\n",
        "        clone_dir = Path(temp_dir) / \"repo\"\n",
        "        try:\n",
        "            clone_repository(repo_url, clone_dir)\n",
        "        except Exception as e:\n",
        "            return f\"Error cloning repository: {e}\"\n",
        "\n",
        "        try:\n",
        "            # Convert the code base into a structured markdown text.\n",
        "            code_base = map_codebase_to_text(clone_dir)\n",
        "        except Exception as e:\n",
        "            return f\"Error processing code base: {e}\"\n",
        "\n",
        "        # Use OpenAIAssistant to analyze the code base.\n",
        "        try:\n",
        "            # The model name here should match your environment variable or chosen model.\n",
        "            model_name = os.environ.get(\"MODEL_NAME\", \"gpt-4\")\n",
        "            # You can also pass other configurations using environment variables as needed.\n",
        "            with AzureOpenAIAssistant(SoftwareArchitecture, model=model_name) as assistant:\n",
        "                software_architecture = assistant.process(code_base=code_base)\n",
        "                markdown_output = software_architecture.to_markdown()\n",
        "                return markdown_output\n",
        "        except Exception as e:\n",
        "            return f\"Error analyzing code base with LLM: {e}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title --\n",
        "\n",
        "# def analyze_repository(repo_url: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Clones the GitHub repository, converts its code base to text, then uses an LLM to analyze the software architecture.\n",
        "#     Returns the analysis as markdown.\n",
        "#     \"\"\"\n",
        "#     # Create a temporary directory for cloning the repo.\n",
        "#     with tempfile.TemporaryDirectory() as temp_dir:\n",
        "#         clone_dir = Path(temp_dir) / \"repo\"\n",
        "#         try:\n",
        "#             clone_repository(repo_url, clone_dir)\n",
        "#         except Exception as e:\n",
        "#             return f\"Error cloning repository: {e}\"\n",
        "\n",
        "#         try:\n",
        "#             # Convert the code base into a structured markdown text.\n",
        "#             code_base = map_codebase_to_text(clone_dir)\n",
        "#         except Exception as e:\n",
        "#             return f\"Error processing code base: {e}\"\n",
        "\n",
        "#         # Use OpenAI's API to analyze the code base.\n",
        "#         try:\n",
        "#             # Set your Azure OpenAI configuration\n",
        "#             openai.api_type = \"azure\"\n",
        "#             openai.api_base = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
        "#             openai.api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
        "#             openai.api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
        "\n",
        "#             # Define the prompt for the model\n",
        "#             prompt = (\n",
        "#                 \"You are a software architect.\\n\\n\"\n",
        "#                 \"Analyze the following code base and provide a detailed description of the software architecture, \"\n",
        "#                 \"including high-level modules and their sub-modules:\\n\\n\"\n",
        "#                 f\"{code_base}\\n\\n\"\n",
        "#                 \"Provide the analysis in a structured markdown format.\"\n",
        "#             )\n",
        "\n",
        "#             # Call the OpenAI API\n",
        "#             response = openai.Completion.create(\n",
        "#                 engine=os.environ.get(\"MODEL_NAME\", \"gpt-4\"),  # Replace with your model deployment name\n",
        "#                 prompt=prompt,\n",
        "#                 max_tokens=1000,  # Adjust based on your needs\n",
        "#                 temperature=0.5\n",
        "#             )\n",
        "\n",
        "#             # Extract the generated text\n",
        "#             analysis = response.choices[0].text.strip()\n",
        "#             return analysis\n",
        "#         except Exception as e:\n",
        "#             return f\"Error analyzing code base with LLM: {e}\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JKfUO9b_qfFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "ZnMVgi7Gjnua",
        "outputId": "c8981ab6-95f4-4999-85a9-69c29a725001",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://f3680193d6689ac05d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f3680193d6689ac05d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://f3680193d6689ac05d.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#@title Gradio app\n",
        "\n",
        "# -----------------------------\n",
        "# Gradio Interface\n",
        "# -----------------------------\n",
        "def gradio_analyze(repo_url: str) -> str:\n",
        "    \"\"\"\n",
        "    Gradio interface function: Given a GitHub repo URL, return the analysis.\n",
        "    \"\"\"\n",
        "    if not repo_url.startswith(\"http\"):\n",
        "        return \"Please provide a valid GitHub repository URL.\"\n",
        "    return analyze_repository(repo_url)\n",
        "\n",
        "# Create and launch the Gradio interface.\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_analyze,\n",
        "    inputs=gr.Textbox(label=\"GitHub Repository URL\", placeholder=\"https://github.com/username/repository\"),\n",
        "    outputs=gr.Textbox(label=\"Architecture Analysis (Markdown)\"),\n",
        "    title=\"Codebase Analyzer with LLMs\",\n",
        "    description=(\n",
        "        \"Set your secrets (AZURE_OPENAI_API_KEY, MODEL_NAME, AZURE_OPENAI_API_TYPE, etc.) in the Colab secrets. \"\n",
        "        \"Then provide the URL of a GitHub repository to analyze its code base and extract the software architecture.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "iface.launch(debug= True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -- END NOTEBOOK"
      ],
      "metadata": {
        "id": "eyigSrW2sR9o"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNszLU70LUVngJ8e2HovPG6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}